# Part 1: æ¨¡å‹è®­ç»ƒè¯¦ç»†è¯´æ˜æ–‡æ¡£

## ğŸ“Œ æ¦‚è¿°

**ç›®æ ‡**: ä½¿ç”¨ TensorFlow 2.16 å’Œ Keras 3 è®­ç»ƒä¸€ä¸ªè½»é‡çº§ CNN æ¨¡å‹ï¼Œç”¨äº MNIST æ‰‹å†™æ•°å­—è¯†åˆ«ã€‚

**è¾“å…¥**: MNIST æ•°æ®é›†ï¼ˆ60,000 è®­ç»ƒå›¾åƒ + 10,000 æµ‹è¯•å›¾åƒï¼‰  
**è¾“å‡º**: `mnist_cnn_model.keras` æ¨¡å‹æ–‡ä»¶

---

## ğŸ› ï¸ ç¯å¢ƒè¦æ±‚

### è½¯ä»¶ä¾èµ–
```bash
# Conda ç¯å¢ƒåç§°: mls-trans
TensorFlow: 2.16.x
Keras: 3.x
NumPy: æœ€æ–°ç¨³å®šç‰ˆ
Matplotlib: ç”¨äºå¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹
```

### å®‰è£…å‘½ä»¤
```bash
conda create -n mls-trans python=3.10
conda activate mls-trans
pip install tensorflow==2.16.0 keras matplotlib numpy
```

---

## ğŸ“‚ æ–‡ä»¶è¯´æ˜

### ä¸»æ–‡ä»¶: `part1_tensorflow.py`

**æ–‡ä»¶ç»“æ„**:
```
part1_tensorflow.py
â”œâ”€â”€ create_model()           # æ„å»º CNN æ¨¡å‹æ¶æ„
â”œâ”€â”€ load_and_preprocess_data() # åŠ è½½å¹¶é¢„å¤„ç† MNIST æ•°æ®
â”œâ”€â”€ train_model()            # è®­ç»ƒæ¨¡å‹
â”œâ”€â”€ plot_history()           # å¯è§†åŒ–è®­ç»ƒå†å²
â””â”€â”€ main()                   # ä¸»æ‰§è¡Œæµç¨‹
```

---

## ğŸ—ï¸ æ¨¡å‹æ¶æ„è¯¦è§£

### ç½‘ç»œç»“æ„

```python
Sequential Model:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input: (28, 28, 1)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Conv2D(8 filters, 3x3, ReLU)            â”‚  â† 80 å‚æ•°
â”‚   Output: (26, 26, 8)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ MaxPooling2D(2x2)                       â”‚  â† 0 å‚æ•°
â”‚   Output: (13, 13, 8)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Flatten()                               â”‚  â† 0 å‚æ•°
â”‚   Output: (1352,)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dense(16, ReLU)                         â”‚  â† 21,648 å‚æ•°
â”‚   Output: (16,)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dense(10, Softmax)                      â”‚  â† 170 å‚æ•°
â”‚   Output: (10,)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Total Parameters: 21,898 (85.54 KB)
```

### å±‚çº§åˆ†æ

#### 1. Conv2D å±‚
```python
keras.layers.Conv2D(8, (3, 3), activation='relu', input_shape=(28, 28, 1))
```
- **ä½œç”¨**: æå–å›¾åƒçš„å±€éƒ¨ç‰¹å¾ï¼ˆè¾¹ç¼˜ã€çº¹ç†ï¼‰
- **å‚æ•°æ•°é‡**: `(3Ã—3Ã—1 + 1) Ã— 8 = 80`
  - 3Ã—3 å·ç§¯æ ¸ Ã— 1 è¾“å…¥é€šé“ Ã— 8 è¾“å‡ºé€šé“ + 8 åç½®
- **è¾“å‡ºå½¢çŠ¶**: (26, 26, 8)
  - 26 = 28 - 3 + 1ï¼ˆvalid å¡«å……ï¼‰

#### 2. MaxPooling2D å±‚
```python
keras.layers.MaxPooling2D((2, 2))
```
- **ä½œç”¨**: ä¸‹é‡‡æ ·ï¼Œå‡å°‘å‚æ•°é‡ï¼Œæå–ä¸»è¦ç‰¹å¾
- **è¾“å‡ºå½¢çŠ¶**: (13, 13, 8)
  - 13 = 26 / 2

#### 3. Flatten å±‚
```python
keras.layers.Flatten()
```
- **ä½œç”¨**: å°† 3D ç‰¹å¾å›¾å±•å¹³ä¸º 1D å‘é‡
- **è¾“å‡ºå½¢çŠ¶**: (1352,)
  - 1352 = 13 Ã— 13 Ã— 8

#### 4. Dense(16) å±‚
```python
keras.layers.Dense(16, activation='relu')
```
- **ä½œç”¨**: å…¨è¿æ¥å±‚ï¼Œå­¦ä¹ ç‰¹å¾ç»„åˆ
- **å‚æ•°æ•°é‡**: `1352 Ã— 16 + 16 = 21,648`

#### 5. Dense(10) è¾“å‡ºå±‚
```python
keras.layers.Dense(10, activation='softmax')
```
- **ä½œç”¨**: åˆ†ç±»å±‚ï¼Œè¾“å‡º 10 ä¸ªç±»åˆ«çš„æ¦‚ç‡åˆ†å¸ƒ
- **å‚æ•°æ•°é‡**: `16 Ã— 10 + 10 = 170`

---

## ğŸ“Š æ•°æ®é¢„å¤„ç†æµç¨‹

### 1. åŠ è½½æ•°æ®
```python
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
```
- **è®­ç»ƒé›†**: 60,000 å¼  28Ã—28 ç°åº¦å›¾åƒ
- **æµ‹è¯•é›†**: 10,000 å¼  28Ã—28 ç°åº¦å›¾åƒ

### 2. å½’ä¸€åŒ–
```python
x_train = x_train.astype("float32") / 255.0
x_test = x_test.astype("float32") / 255.0
```
- **ç›®çš„**: å°†åƒç´ å€¼ä» [0, 255] å½’ä¸€åŒ–åˆ° [0, 1]
- **å¥½å¤„**: åŠ é€Ÿæ¢¯åº¦ä¸‹é™æ”¶æ•›

### 3. æ·»åŠ é€šé“ç»´åº¦
```python
x_train = np.expand_dims(x_train, -1)  # (60000, 28, 28) â†’ (60000, 28, 28, 1)
x_test = np.expand_dims(x_test, -1)    # (10000, 28, 28) â†’ (10000, 28, 28, 1)
```
- **ç›®çš„**: CNN éœ€è¦æ˜¾å¼çš„é€šé“ç»´åº¦ï¼ˆç°åº¦å›¾ä¸º 1 é€šé“ï¼‰

---

## ğŸš€ è®­ç»ƒé…ç½®

### ç¼–è¯‘é…ç½®
```python
model.compile(
    optimizer='adam',              # è‡ªé€‚åº”å­¦ä¹ ç‡ä¼˜åŒ–å™¨
    loss='sparse_categorical_crossentropy',  # å¤šåˆ†ç±»äº¤å‰ç†µæŸå¤±
    metrics=['accuracy']           # ç›‘æ§å‡†ç¡®ç‡
)
```

### è®­ç»ƒå‚æ•°
```python
history = model.fit(
    x_train, y_train,
    epochs=5,                      # è®­ç»ƒ 5 è½®
    validation_data=(x_test, y_test)  # æ¯è½®ç»“æŸååœ¨æµ‹è¯•é›†ä¸ŠéªŒè¯
)
```

---

## ğŸ“ˆ é¢„æœŸè®­ç»ƒç»“æœ

### å…¸å‹è¾“å‡ºç¤ºä¾‹
```
Epoch 1/5
1875/1875 [==============================] - 15s 8ms/step 
    - loss: 0.2314 - accuracy: 0.9327 - val_loss: 0.0894 - val_accuracy: 0.9726
Epoch 2/5
1875/1875 [==============================] - 14s 7ms/step 
    - loss: 0.0766 - accuracy: 0.9763 - val_loss: 0.0656 - val_accuracy: 0.9798
Epoch 3/5
1875/1875 [==============================] - 14s 7ms/step 
    - loss: 0.0550 - accuracy: 0.9826 - val_loss: 0.0591 - val_accuracy: 0.9816
Epoch 4/5
1875/1875 [==============================] - 14s 7ms/step 
    - loss: 0.0436 - accuracy: 0.9859 - val_loss: 0.0553 - val_accuracy: 0.9826
Epoch 5/5
1875/1875 [==============================] - 14s 7ms/step 
    - loss: 0.0361 - accuracy: 0.9882 - val_loss: 0.0530 - val_accuracy: 0.9834
```

### æ€§èƒ½æŒ‡æ ‡
- **æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡**: ~98.8%
- **æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡**: ~98.3%
- **è®­ç»ƒæ—¶é—´**: çº¦ 70 ç§’ï¼ˆApple M ç³»åˆ—èŠ¯ç‰‡ï¼‰

---

## ğŸ“Š å¯è§†åŒ–åˆ†æ

### è®­ç»ƒæ›²çº¿
`plot_history()` å‡½æ•°ç”Ÿæˆä¸¤ä¸ªå›¾è¡¨ï¼š

#### 1. å‡†ç¡®ç‡æ›²çº¿
- **è®­ç»ƒå‡†ç¡®ç‡**: æŒç»­ä¸Šå‡ï¼Œä» 93% â†’ 98.8%
- **éªŒè¯å‡†ç¡®ç‡**: ä» 97% â†’ 98.3%
- **è§‚å¯Ÿ**: æ— æ˜æ˜¾è¿‡æ‹Ÿåˆï¼ˆè®­ç»ƒå’ŒéªŒè¯æ›²çº¿æ¥è¿‘ï¼‰

#### 2. æŸå¤±æ›²çº¿
- **è®­ç»ƒæŸå¤±**: ä» 0.23 ä¸‹é™åˆ° 0.036
- **éªŒè¯æŸå¤±**: ä» 0.089 ä¸‹é™åˆ° 0.053
- **è§‚å¯Ÿ**: éªŒè¯æŸå¤±ç•¥é«˜äºè®­ç»ƒæŸå¤±ï¼Œä½†å·®è·è¾ƒå°

---

## ğŸ’¾ æ¨¡å‹ä¿å­˜

### è¾“å‡ºæ–‡ä»¶
```python
# é»˜è®¤æƒ…å†µä¸‹ï¼ŒKeras 3 ä¼šè‡ªåŠ¨ä¿å­˜ä¸º .keras æ ¼å¼
model.save("mnist_cnn_model.keras")
```

### æ–‡ä»¶ä¿¡æ¯
- **æ–‡ä»¶å**: `mnist_cnn_model.keras`
- **æ–‡ä»¶å¤§å°**: ~286 KB
- **æ ¼å¼**: Keras 3 åŸç”Ÿæ ¼å¼ï¼ˆåŸºäº ZIP çš„ HDF5ï¼‰
- **åŒ…å«å†…å®¹**:
  - æ¨¡å‹æ¶æ„ï¼ˆJSON æ ¼å¼ï¼‰
  - æƒé‡å‚æ•°ï¼ˆHDF5 æ ¼å¼ï¼‰
  - ä¼˜åŒ–å™¨çŠ¶æ€
  - è®­ç»ƒé…ç½®

---

## ğŸ” å…³é”®ä»£ç è§£æ

### 1. æ¨¡å‹åˆ›å»ºå‡½æ•°
```python
def create_model():
    model = keras.Sequential([
        keras.layers.Conv2D(8, (3, 3), activation='relu', input_shape=(28, 28, 1)),
        keras.layers.MaxPooling2D((2, 2)),
        keras.layers.Flatten(),
        keras.layers.Dense(16, activation='relu'),
        keras.layers.Dense(10, activation='softmax')
    ])
    model.compile(
        optimizer='adam',
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    return model
```
**è¦ç‚¹**:
- ä½¿ç”¨ Sequential APIï¼ˆé€‚åˆçº¿æ€§å †å çš„å±‚ï¼‰
- æ¿€æ´»å‡½æ•°é€‰æ‹©ï¼šReLUï¼ˆéšè—å±‚ï¼‰+ Softmaxï¼ˆè¾“å‡ºå±‚ï¼‰
- æŸå¤±å‡½æ•°ï¼š`sparse_categorical_crossentropy`ï¼ˆæ ‡ç­¾ä¸ºæ•´æ•°æ—¶ä½¿ç”¨ï¼‰

### 2. æ•°æ®é¢„å¤„ç†å‡½æ•°
```python
def load_and_preprocess_data():
    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
    x_train = x_train.astype("float32") / 255.0
    x_test = x_test.astype("float32") / 255.0
    x_train = np.expand_dims(x_train, -1)
    x_test = np.expand_dims(x_test, -1)
    return x_train, y_train, x_test, y_test
```
**è¦ç‚¹**:
- ç±»å‹è½¬æ¢ï¼š`uint8` â†’ `float32`ï¼ˆé¿å…æ•´æ•°é™¤æ³•é—®é¢˜ï¼‰
- å½’ä¸€åŒ–ï¼šé™¤ä»¥ 255.0ï¼ˆè€Œé 255ï¼Œç¡®ä¿æµ®ç‚¹è¿ç®—ï¼‰
- ç»´åº¦æ‰©å±•ï¼š`-1` è¡¨ç¤ºåœ¨æœ€åæ·»åŠ ç»´åº¦

---

## âš ï¸ å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### é—®é¢˜ 1: Keras 3 å¯¼å…¥é”™è¯¯
```
ImportError: cannot import name 'Sequential' from 'keras'
```
**è§£å†³æ–¹æ¡ˆ**:
```bash
# ç¡®ä¿ä½¿ç”¨ TensorFlow 2.16+ 
pip install tensorflow==2.16.0
# Keras 3 å·²é›†æˆåœ¨ TensorFlow ä¸­
```

### é—®é¢˜ 2: å†…å­˜ä¸è¶³
```
ResourceExhaustedError: OOM when allocating tensor
```
**è§£å†³æ–¹æ¡ˆ**:
```python
# å‡å°æ‰¹æ¬¡å¤§å°
history = model.fit(x_train, y_train, batch_size=32, epochs=5)
```

### é—®é¢˜ 3: è®­ç»ƒé€Ÿåº¦æ…¢
**ä¼˜åŒ–å»ºè®®**:
- ä½¿ç”¨ GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
- å‡å°‘è®­ç»ƒè½®æ¬¡ï¼ˆ5 è½®é€šå¸¸å·²è¶³å¤Ÿï¼‰
- ä½¿ç”¨æ•°æ®å¢å¼ºæ—¶è€ƒè™‘å¹¶è¡ŒåŠ è½½

---

## ğŸ¯ ä¸‹ä¸€æ­¥æ“ä½œ

å®Œæˆ Part 1 åï¼Œéœ€è¦å¯¼å‡ºæƒé‡ä»¥ä¾¿åœ¨ TensorFlow 2.15 ç¯å¢ƒä¸­ä½¿ç”¨ï¼š

```python
import keras
m = keras.saving.load_model("mnist_cnn_model.keras")
m.save_weights("mnist_cnn.weights.h5")
print("æƒé‡å·²å¯¼å‡º: mnist_cnn.weights.h5")
```

**åŸå› **: Keras 3 ä¸ TensorFlow 2.15 çš„ TFLite è½¬æ¢å™¨å­˜åœ¨å…¼å®¹æ€§é—®é¢˜ï¼Œéœ€è¦å…ˆå¯¼å‡ºæƒé‡ï¼Œå†åœ¨ TF 2.15 ç¯å¢ƒä¸­é‡å»ºæ¨¡å‹ã€‚

---

## ğŸ“ è¿è¡Œæ£€æŸ¥æ¸…å•

- [ ] ç¡®è®¤ Conda ç¯å¢ƒä¸º `mls-trans`
- [ ] ç¡®è®¤ TensorFlow ç‰ˆæœ¬ä¸º 2.16.x
- [ ] ç¡®è®¤ Keras ç‰ˆæœ¬ä¸º 3.x
- [ ] è¿è¡Œ `python part1_tensorflow.py`
- [ ] æ£€æŸ¥ç”Ÿæˆçš„ `mnist_cnn_model.keras` æ–‡ä»¶
- [ ] éªŒè¯æ¨¡å‹å¤§å°çº¦ä¸º 286 KB
- [ ] ç¡®è®¤è®­ç»ƒå‡†ç¡®ç‡ > 98%
- [ ] å¯¼å‡ºæƒé‡åˆ° `mnist_cnn.weights.h5`

---

## ğŸ“š å‚è€ƒèµ„æº

- [TensorFlow å®˜æ–¹æ–‡æ¡£](https://www.tensorflow.org/guide)
- [Keras 3 è¿ç§»æŒ‡å—](https://keras.io/guides/migrating_to_keras_3/)
- [MNIST æ•°æ®é›†ä»‹ç»](http://yann.lecun.com/exdb/mnist/)
- [CNN æ¶æ„è¯¦è§£](https://cs231n.github.io/convolutional-networks/)
