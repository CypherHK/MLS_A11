# Part 3: åµŒå…¥å¼éƒ¨ç½²è¯¦ç»†è¯´æ˜æ–‡æ¡£

## ğŸ“Œ æ¦‚è¿°

**ç›®æ ‡**: åœ¨ macOS å¹³å°ä½¿ç”¨ TensorFlow Lite Micro (TFLM) è¿è¡Œé‡åŒ–æ¨¡å‹è¿›è¡Œæœ¬åœ°æ¨ç†

**è¾“å…¥**:
- `mnist_model_quantized.tflite` (INT8 é‡åŒ–æ¨¡å‹, 25 KB)
- TFLite Micro åº“æºç 

**è¾“å‡º**:
- `model_data.cc` / `model_data.h` (æ¨¡å‹ C æ•°ç»„)
- `gen_micro_mutable_op_resolver.h` (ç®—å­è§£æå™¨)
- `mnist_micro` (å¯æ‰§è¡Œæ¨ç†ç¨‹åº)

---

## ï¿½ï¿½ï¸ ç¯å¢ƒè¦æ±‚

### ç³»ç»Ÿä¾èµ–
```bash
æ“ä½œç³»ç»Ÿ: macOS (æœ¬é¡¹ç›®é’ˆå¯¹ ARM64 æ¶æ„)
ç¼–è¯‘å™¨: Clang++ (Apple Silicon é»˜è®¤)
æ„å»ºå·¥å…·: Make, Bazel
Python: 3.9+ (ç”¨äºè„šæœ¬å·¥å…·)
```

### TFLite Micro æºç 
```bash
# å…‹éš† TFLM ä»“åº“
cd /Users/wangyucheng/Projects/MLS_A11
git clone https://github.com/tensorflow/tflite-micro.git
```

**ç›®å½•ç»“æ„**:
```
MLS_A11/
â”œâ”€â”€ mnist_model_quantized.tflite   # é‡åŒ–æ¨¡å‹
â”œâ”€â”€ transToArray.sh                # æ¨¡å‹è½¬ C æ•°ç»„è„šæœ¬
â”œâ”€â”€ find.sh                        # ç®—å­è§£æå™¨ç”Ÿæˆè„šæœ¬
â”œâ”€â”€ model_inference.cc             # æ¨ç†ä¸»ç¨‹åº
â”œâ”€â”€ Makefile                       # æ„å»ºé…ç½®
â””â”€â”€ tflite-micro/                  # TFLM æºç 
    â”œâ”€â”€ tensorflow/lite/...
    â””â”€â”€ BUILD, WORKSPACE
```

---

## ğŸ”„ éƒ¨ç½²æµç¨‹è¯¦è§£

### å®Œæ•´å·¥ä½œæµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 1: è½¬æ¢æ¨¡å‹ä¸º C æ•°ç»„                                   â”‚
â”‚  transToArray.sh â†’ model_data.cc / model_data.h             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 2: ç”Ÿæˆç®—å­è§£æå™¨                                      â”‚
â”‚  find.sh â†’ gen_micro_mutable_op_resolver.h                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 3: ç¼–å†™æ¨ç†ä»£ç                                         â”‚
â”‚  model_inference.cc (åŠ è½½æ¨¡å‹ã€å‡†å¤‡è¾“å…¥ã€æ‰§è¡Œæ¨ç†)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 4: æ„å»º TFLM é™æ€åº“                                    â”‚
â”‚  make lib â†’ libtensorflow-microlite.a                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 5: ç¼–è¯‘é“¾æ¥æ¨ç†ç¨‹åº                                    â”‚
â”‚  make all â†’ mnist_micro (å¯æ‰§è¡Œæ–‡ä»¶)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 6: è¿è¡Œæ¨ç†                                            â”‚
â”‚  ./mnist_micro â†’ è¾“å‡ºé¢„æµ‹ç»“æœ                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ å…³é”®æ­¥éª¤è¯¦è§£

### Step 1: æ¨¡å‹è½¬ C æ•°ç»„

#### è„šæœ¬: `transToArray.sh`

```bash
python tensorflow/tensorflow/lite/python/convert_file_to_c_source.py \
  --input_tflite_file mnist_model_quantized.tflite \
  --output_source_file model_data.cc \
  --output_header_file model_data.h \
  --array_variable_name g_mnist_model
```

**æ‰§è¡Œ**:
```bash
cd /Users/wangyucheng/Projects/MLS_A11/tflite-micro
bash ../transToArray.sh
```

**ç”Ÿæˆæ–‡ä»¶**:

1. **`model_data.h`** (å¤´æ–‡ä»¶):
```cpp
#ifndef TENSORFLOW_LITE_UTIL_G_MNIST_MODEL_DATA_H_
#define TENSORFLOW_LITE_UTIL_G_MNIST_MODEL_DATA_H_

extern const unsigned char g_mnist_model[];  // æ¨¡å‹æ•°æ®æ•°ç»„
extern const int g_mnist_model_len;          // æ•°ç»„é•¿åº¦

#endif
```

2. **`model_data.cc`** (å®ç°æ–‡ä»¶):
```cpp
#include "model_data.h"

// æ¨¡å‹æ•°æ®ï¼ˆ25304 å­—èŠ‚ï¼‰
alignas(8) const unsigned char g_mnist_model[] = {
  0x1c, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4c, 0x33, // TFL3 æ–‡ä»¶å¤´
  0x00, 0x00, 0x12, 0x00, 0x1c, 0x00, 0x04, 0x00,
  // ... å…± 25304 å­—èŠ‚
};

const int g_mnist_model_len = 25304;
```

**ä¸ºä»€ä¹ˆéœ€è¦è½¬æ¢ä¸º C æ•°ç»„ï¼Ÿ**
- âŒ åµŒå…¥å¼ç³»ç»Ÿé€šå¸¸æ²¡æœ‰æ–‡ä»¶ç³»ç»Ÿï¼ˆæ— æ³• `fopen()`ï¼‰
- âœ… C æ•°ç»„ç¼–è¯‘åˆ°å¯æ‰§è¡Œæ–‡ä»¶çš„ `.rodata` æ®µï¼ˆåªè¯»æ•°æ®ï¼‰
- âœ… ç›´æ¥ä»å†…å­˜è®¿é—®ï¼Œæ— éœ€ I/O æ“ä½œ

---

### Step 2: ç”Ÿæˆç®—å­è§£æå™¨

#### è„šæœ¬: `find.sh`

```bash
#!/bin/bash
cd tflite-micro

MODEL_DIR="/Users/wangyucheng/Projects/MLS_A11"
OUT_DIR="$MODEL_DIR/op_resolver"
mkdir -p "$OUT_DIR"

# ä½¿ç”¨ Bazel å·¥å…·ç”Ÿæˆç®—å­è§£æå™¨
bazel run //tensorflow/lite/micro/tools/gen_micro_mutable_op_resolver:generate_micro_mutable_op_resolver_from_model -- \
  --common_tflite_path="$MODEL_DIR" \
  --input_tflite_files=mnist_model_quantized.tflite \
  --output_dir="$OUT_DIR"
```

**æ‰§è¡Œ**:
```bash
bash find.sh
```

**ç”Ÿæˆæ–‡ä»¶**: `op_resolver/gen_micro_mutable_op_resolver.h`

```cpp
#pragma once

#include "tensorflow/lite/micro/micro_mutable_op_resolver.h"

constexpr int kNumberOperators = 5;  // æ¨¡å‹ä½¿ç”¨ 5 ç§ç®—å­

inline tflite::MicroMutableOpResolver<kNumberOperators> get_resolver()
{
  tflite::MicroMutableOpResolver<kNumberOperators> micro_op_resolver;

  // ä»…æ³¨å†Œæ¨¡å‹å®é™…ä½¿ç”¨çš„ç®—å­
  micro_op_resolver.AddConv2D();          // builtin_code=3
  micro_op_resolver.AddFullyConnected();  // builtin_code=9
  micro_op_resolver.AddMaxPool2D();       // builtin_code=17
  micro_op_resolver.AddReshape();         // builtin_code=22
  micro_op_resolver.AddSoftmax();         // builtin_code=25

  return micro_op_resolver;
}
```

**ä¸ºä»€ä¹ˆéœ€è¦ç®—å­è§£æå™¨ï¼Ÿ**
- TFLite æ¨¡å‹åŒ…å«ç®—å­ç±»å‹ IDï¼ˆå¦‚ `builtin_code=3`ï¼‰
- TFLM éœ€è¦ä¸€ä¸ª**æ³¨å†Œè¡¨**å°† ID æ˜ å°„åˆ°å®é™…çš„ C++ å‡½æ•°å®ç°
- åªæ³¨å†Œéœ€è¦çš„ç®—å­å¯ä»¥å‡å°äºŒè¿›åˆ¶æ–‡ä»¶å¤§å°

**ç®—å­å¯¹åº”å…³ç³»**:
| Builtin Code | ç®—å­åç§° | ä½œç”¨ |
|--------------|---------|------|
| 3 | CONV_2D | 2D å·ç§¯ |
| 9 | FULLY_CONNECTED | å…¨è¿æ¥å±‚ |
| 17 | MAX_POOL_2D | æœ€å¤§æ± åŒ– |
| 22 | RESHAPE | å¼ é‡å½¢çŠ¶å˜æ¢ |
| 25 | SOFTMAX | Softmax æ¿€æ´» |

---

### Step 3: ç¼–å†™æ¨ç†ä»£ç 

#### ä¸»æ–‡ä»¶: `model_inference.cc`

**æ ¸å¿ƒç»“æ„**:

```cpp
// ===== 1. å¤´æ–‡ä»¶å¼•å…¥ =====
#include "tensorflow/lite/micro/micro_interpreter.h"
#include "tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "tensorflow/lite/schema/schema_generated.h"
#include "op_resolver/gen_micro_mutable_op_resolver.h"
#include "model_data.h"

// ===== 2. å…¨å±€é…ç½® =====
constexpr int kTensorArenaSize = 60 * 1024;  // 60KB å†…å­˜æ± 
alignas(16) static uint8_t tensor_arena[kTensorArenaSize];

// ===== 3. ä¸»å‡½æ•° =====
int main() {
  // 3.1 åˆå§‹åŒ–ç›®æ ‡å¹³å°
  tflite::InitializeTarget();

  // 3.2 åŠ è½½æ¨¡å‹
  const tflite::Model* model = tflite::GetModel(g_mnist_model);

  // 3.3 æ³¨å†Œç®—å­
  static tflite::MicroMutableOpResolver<5> resolver;
  resolver.AddConv2D();
  resolver.AddMaxPool2D();
  resolver.AddReshape();
  resolver.AddFullyConnected();
  resolver.AddSoftmax();

  // 3.4 åˆ›å»ºè§£é‡Šå™¨
  tflite::MicroInterpreter interpreter(model, resolver, tensor_arena, kTensorArenaSize);
  interpreter.AllocateTensors();

  // 3.5 å‡†å¤‡è¾“å…¥æ•°æ®
  TfLiteTensor* input = interpreter.input(0);
  // é‡åŒ–è¾“å…¥å›¾åƒï¼ˆè§ä¸‹æ–‡ï¼‰

  // 3.6 æ‰§è¡Œæ¨ç†
  interpreter.Invoke();

  // 3.7 è§£æè¾“å‡º
  TfLiteTensor* output = interpreter.output(0);
  int predicted_class = /* argmax(output) */;

  return 0;
}
```

#### å…³é”®ç»„ä»¶è¯¦è§£

##### 1. Tensor Arenaï¼ˆå¼ é‡å†…å­˜æ± ï¼‰

```cpp
constexpr int kTensorArenaSize = 60 * 1024;  // 60KB
alignas(16) static uint8_t tensor_arena[kTensorArenaSize];
```

**ä½œç”¨**:
- TFLM ä½¿ç”¨**é™æ€å†…å­˜åˆ†é…**ï¼ˆä¸ä½¿ç”¨ `malloc`/`new`ï¼‰
- æ‰€æœ‰ä¸­é—´å¼ é‡ã€æ¿€æ´»å€¼éƒ½ä»è¿™ä¸ªå†…å­˜æ± åˆ†é…
- `alignas(16)` ç¡®ä¿åœ°å€ 16 å­—èŠ‚å¯¹é½ï¼ˆSIMD ä¼˜åŒ–éœ€è¦ï¼‰

**å¦‚ä½•ç¡®å®šå¤§å°ï¼Ÿ**
```cpp
// è¿è¡ŒåæŸ¥çœ‹å®é™…ä½¿ç”¨é‡
MicroPrintf("Tensor arena used: %u bytes", 
            interpreter.arena_used_bytes());
```

**æœ¬é¡¹ç›®å®é™…ä½¿ç”¨**: 8480 å­—èŠ‚ï¼ˆ60KB è¶³å¤Ÿï¼‰

##### 2. è¾“å…¥æ•°æ®é‡åŒ–

```cpp
static void QuantizeToInt8(const uint8_t* src_u8, int8_t* dst_i8, 
                           float scale, int zero_point) {
  for (int i = 0; i < 28*28; ++i) {
    float x01 = static_cast<float>(src_u8[i]) / 255.0f;  // [0, 255] â†’ [0, 1]
    int q = static_cast<int>(std::round(x01 / scale + zero_point));
    if (q < -128) q = -128; 
    if (q > 127) q = 127;
    dst_i8[i] = static_cast<int8_t>(q);
  }
}

// ä½¿ç”¨
uint8_t img_u8[28*28];  // åŸå§‹å›¾åƒï¼ˆ0-255ï¼‰
MakeTestImage(img_u8);  // ç”Ÿæˆæµ‹è¯•å›¾åƒ

TfLiteTensor* input = interpreter.input(0);
QuantizeToInt8(img_u8, input->data.int8, 
               input->params.scale,      // ä»æ¨¡å‹ä¸­è·å–
               input->params.zero_point);
```

**é‡åŒ–å‚æ•°æ¥æº**:
- `scale` å’Œ `zero_point` åœ¨é‡åŒ–æ—¶ç”± TFLite è½¬æ¢å™¨è®¡ç®—
- å­˜å‚¨åœ¨ `.tflite` æ–‡ä»¶çš„ FlatBuffer å…ƒæ•°æ®ä¸­
- è¿è¡Œæ—¶é€šè¿‡ `input->params` è®¿é—®

##### 3. ç”Ÿæˆæµ‹è¯•å›¾åƒ

```cpp
static void MakeTestImage(uint8_t img[28*28]) {
  std::memset(img, 0, 28*28);  // é»‘è‰²èƒŒæ™¯
  
  // åœ¨ä¸­é—´ç”»ä¸€æ¡ç™½è‰²ç«–çº¿ï¼ˆæ¨¡æ‹Ÿæ•°å­— "1"ï¼‰
  for (int y = 4; y < 24; ++y) {
    for (int t = -1; t <= 1; ++t) {
      int x = 14 + t;
      if (x >= 0 && x < 28) 
        img[y*28 + x] = 255;
    }
  }
}
```

**è¾“å‡ºå›¾åƒ**:
```
 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 . . . . . . . . . . . . # # # . . . . . . . . . . . . . 
 . . . . . . . . . . . . # # # . . . . . . . . . . . . . 
 ...ï¼ˆä¸­é—´çœç•¥ï¼‰
 . . . . . . . . . . . . # # # . . . . . . . . . . . . . 
 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
```
ï¼ˆæ¨¡æ‹Ÿæ•°å­— "1"ï¼‰

##### 4. è¾“å‡ºè§£æï¼ˆå¯å‘å¼æ–¹æ³•ï¼‰

```cpp
int out_bytes = output->bytes;
int best_idx = -1;
float best_score = -1e30f;

if (out_bytes == 10) {
  // INT8 è¾“å‡ºï¼ˆ10 ä¸ªå­—èŠ‚ï¼‰
  const int8_t* p = reinterpret_cast<const int8_t*>(output->data.raw);
  for (int i = 0; i < 10; ++i) {
    int v = (int)p[i];
    if (v > best_score) { 
      best_score = (float)v; 
      best_idx = i; 
    }
  }
} else if (out_bytes == 40) {
  // Float32 è¾“å‡ºï¼ˆ10 ä¸ªæµ®ç‚¹æ•° Ã— 4 å­—èŠ‚ï¼‰
  const float* p = reinterpret_cast<const float*>(output->data.raw);
  for (int i = 0; i < 10; ++i) {
    if (p[i] > best_score) { 
      best_score = p[i]; 
      best_idx = i; 
    }
  }
}

MicroPrintf("Predicted class = %d", best_idx);
```

**ä¸ºä»€ä¹ˆä½¿ç”¨å¯å‘å¼ï¼Ÿ**
- è¾“å‡ºç±»å‹ï¼ˆINT8 æˆ– Float32ï¼‰å–å†³äºæ¨¡å‹è½¬æ¢é…ç½®
- é€šè¿‡ `bytes` å­—æ®µåˆ¤æ–­ç±»å‹æ›´å¥å£®
- Argmax æ“ä½œåœ¨ä¸¤ç§ç±»å‹ä¸‹éƒ½é€‚ç”¨

---

### Step 4: æ„å»º TFLM é™æ€åº“

#### Makefile é…ç½®

```makefile
# åº“æ„å»ºç›®æ ‡
lib:
	@echo "Building TFLM static lib via tools/make ..."
	@cd $(TFLM_ROOT) && \
	  make -f tensorflow/lite/micro/tools/make/Makefile TARGET=osx microlite -j8
```

**æ‰§è¡Œ**:
```bash
make lib
```

**è¾“å‡ºæ–‡ä»¶**:
```
tflite-micro/gen/osx_arm64_default_gcc/lib/libtensorflow-microlite.a
```

**åº“æ–‡ä»¶å¤§å°**: ~12 MBï¼ˆåŒ…å«æ‰€æœ‰ TFLM æ ¸å¿ƒåŠŸèƒ½ï¼‰

**æ„å»ºè¿‡ç¨‹**:
1. ç¼–è¯‘ TFLM æ ¸å¿ƒä»£ç ï¼ˆè§£é‡Šå™¨ã€å†…å­˜ç®¡ç†ï¼‰
2. ç¼–è¯‘æ‰€æœ‰ç®—å­å®ç°ï¼ˆConv2D, Dense, Softmax ç­‰ï¼‰
3. ç¼–è¯‘ä¾èµ–åº“ï¼ˆFlatBuffersã€gemmlowpã€ruyï¼‰
4. æ‰“åŒ…ä¸ºé™æ€åº“ `.a` æ–‡ä»¶

---

### Step 5: ç¼–è¯‘æ¨ç†ç¨‹åº

#### Makefile é…ç½®

```makefile
CXX := clang++
CXXFLAGS := -O3 -std=c++17 -DNDEBUG -DTF_LITE_MICRO_DEBUG_LOG -DTF_LITE_STATIC_MEMORY

INCS := \
  -I$(TFLM_ROOT) \
  -I$(TFLM_ROOT)/tensorflow/lite \
  -I$(TFLM_ROOT)/tensorflow/lite/micro \
  -I$(TFLM_ROOT)/tensorflow/lite/micro/tools/make/downloads/flatbuffers/include \
  -I$(TFLM_ROOT)/tensorflow/lite/micro/tools/make/downloads/gemmlowp \
  -I$(TFLM_ROOT)/tensorflow/lite/micro/tools/make/downloads/ruy

SRCS := model_inference.cc model_data.cc
LIB := $(TFLM_ROOT)/gen/osx_arm64_default_gcc/lib/libtensorflow-microlite.a

$(BIN): $(SRCS) | lib
	$(CXX) $(CXXFLAGS) $(INCS) $(SRCS) -o $@ $(LIB) $(LDFLAGS)
```

**æ‰§è¡Œ**:
```bash
make all
```

**è¾“å‡ºæ–‡ä»¶**: `mnist_micro` (çº¦ 1.2 MB)

**ç¼–è¯‘å‚æ•°è¯¦è§£**:
| å‚æ•° | ä½œç”¨ |
|------|------|
| `-O3` | æœ€é«˜çº§åˆ«ä¼˜åŒ–ï¼ˆé€Ÿåº¦ä¼˜å…ˆï¼‰ |
| `-std=c++17` | ä½¿ç”¨ C++17 æ ‡å‡† |
| `-DNDEBUG` | ç¦ç”¨ assertï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰ |
| `-DTF_LITE_MICRO_DEBUG_LOG` | å¯ç”¨ TFLM æ—¥å¿— |
| `-DTF_LITE_STATIC_MEMORY` | ä½¿ç”¨é™æ€å†…å­˜åˆ†é… |

---

### Step 6: è¿è¡Œæ¨ç†

```bash
./mnist_micro
```

**å®Œæ•´è¾“å‡º**:
```
ENUM CHECK: kTfLiteInt8=9, schema INT8=9, schema FLOAT32=0
Model buffer length: 25304 bytes
Flatbuffer input tensor index=0, type=9
Operators in model (builtin codes):
  #0 : builtin_code=3   (CONV_2D)
  #1 : builtin_code=17  (MAX_POOL_2D)
  #2 : builtin_code=22  (RESHAPE)
  #3 : builtin_code=9   (FULLY_CONNECTED)
  #4 : builtin_code=9   (FULLY_CONNECTED)
  #5 : builtin_code=25  (SOFTMAX)
Tensor arena used: 8480 bytes (arena size: 61440 bytes)
Input (runtime): type=9, bytes=784, scale=0.003922, zero_point=-128
Wrote INT8 input using scale=0.003922, zero_point=-128
Invoke successful!
Output Tensor:
  type=9, bytes=10
  dims(size=2): [1, 10, -1, -1]
  scale=0.003906, zero_point=-128
Output heuristic: 10x INT8/UINT8 bytes
Predicted class = 1
```

**è¾“å‡ºè§£è¯»**:

1. **æ¨¡å‹éªŒè¯**:
   - è¾“å…¥ç±»å‹ INT8 (type=9) âœ…
   - æ¨¡å‹å¤§å° 25304 å­—èŠ‚ âœ…

2. **ç®—å­æ£€æŸ¥**:
   - æ‰€æœ‰ 6 ä¸ªç®—å­éƒ½å·²æ³¨å†Œ âœ…

3. **å†…å­˜ä½¿ç”¨**:
   - Arena å®é™…ä½¿ç”¨ 8480/61440 å­—èŠ‚ï¼ˆä»… 13.8%ï¼‰
   - å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–å†…å­˜é…ç½®

4. **æ¨ç†ç»“æœ**:
   - é¢„æµ‹ç±»åˆ« = 1ï¼ˆæ•°å­— "1"ï¼‰âœ…
   - ä¸æµ‹è¯•å›¾åƒä¸€è‡´

---

## ğŸ” æ·±åº¦æŠ€æœ¯åˆ†æ

### 1. FlatBuffer æ¨¡å‹æ ¼å¼

**ç»“æ„å±‚æ¬¡**:
```
TFLite æ¨¡å‹ (FlatBuffer)
â”œâ”€â”€ version: 3
â”œâ”€â”€ operator_codes[]        # ç®—å­å®šä¹‰
â”‚   â”œâ”€â”€ [0] builtin_code=3  (CONV_2D)
â”‚   â”œâ”€â”€ [1] builtin_code=17 (MAX_POOL_2D)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ subgraphs[]             # è®¡ç®—å›¾
â”‚   â””â”€â”€ [0] main_graph
â”‚       â”œâ”€â”€ inputs: [0]      # è¾“å…¥å¼ é‡ç´¢å¼•
â”‚       â”œâ”€â”€ outputs: [10]    # è¾“å‡ºå¼ é‡ç´¢å¼•
â”‚       â”œâ”€â”€ tensors[]        # å¼ é‡å®šä¹‰
â”‚       â”‚   â”œâ”€â”€ [0] input: shape=[1,28,28,1], type=INT8
â”‚       â”‚   â”œâ”€â”€ [1] conv_weight: shape=[8,3,3,1], type=INT8
â”‚       â”‚   â””â”€â”€ ...
â”‚       â””â”€â”€ operators[]      # ç®—å­å®ä¾‹
â”‚           â”œâ”€â”€ [0] CONV_2D: inputs=[0,1,2], outputs=[3]
â”‚           â””â”€â”€ ...
â””â”€â”€ buffers[]               # æƒé‡æ•°æ®
    â”œâ”€â”€ [0] <empty>
    â”œâ”€â”€ [1] <conv2d weights: 72 bytes>
    â””â”€â”€ ...
```

**éªŒè¯å·¥å…·**:
```bash
# ä½¿ç”¨ xxd æŸ¥çœ‹æ–‡ä»¶å¤´
xxd mnist_model_quantized.tflite | head -5

# åº”è¯¥çœ‹åˆ°:
# 00000000: 1c00 0000 5446 4c33 ...  # TFL3 (TFLite v3)
```

### 2. é‡åŒ–å‚æ•°ä¼ é€’é“¾è·¯

```
[Part 2] TFLite è½¬æ¢å™¨
   â””â”€> ç»Ÿè®¡æ¿€æ´»å€¼èŒƒå›´ï¼ˆä½¿ç”¨ä»£è¡¨æ€§æ•°æ®é›†ï¼‰
       â””â”€> è®¡ç®— scale & zero_point
           â””â”€> å†™å…¥ FlatBuffer å…ƒæ•°æ®

                     â†“

[Part 3] TFLM è¿è¡Œæ—¶
   â””â”€> è§£æ FlatBuffer
       â””â”€> è¯»å–é‡åŒ–å‚æ•°
           â””â”€> input->params.scale / zero_point
               â””â”€> ç”¨äºè¾“å…¥é‡åŒ–å’Œè¾“å‡ºåé‡åŒ–
```

**ç¤ºä¾‹å‚æ•°**:
```cpp
// è¾“å…¥å¼ é‡é‡åŒ–å‚æ•°
scale = 0.003922  (çº¦ 1/255)
zero_point = -128

// é‡åŒ–å…¬å¼
quantized = round(normalized_value / 0.003922 - 128)

// ç¤ºä¾‹
pixel=255 (ç™½è‰²) â†’ normalized=1.0 â†’ quantized=127
pixel=0   (é»‘è‰²) â†’ normalized=0.0 â†’ quantized=-128
```

### 3. å†…å­˜å¸ƒå±€ä¼˜åŒ–

**Tensor Arena åˆ†é…ç­–ç•¥**:
```
tensor_arena[60KB]
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æŒä¹…å¼ é‡ (persistent tensors)           â”‚ â† æƒé‡ã€åç½®
â”‚ - conv2d_weights (72 bytes)             â”‚
â”‚ - dense_weights (21648 bytes)           â”‚
â”‚ - ...                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ä¸´æ—¶å¼ é‡ (scratch tensors)              â”‚ â† ä¸­é—´æ¿€æ´»å€¼
â”‚ - conv2d_output (1352 bytes)            â”‚
â”‚ - pooling_output (676 bytes)            â”‚
â”‚ - ...ï¼ˆé‡ç”¨å†…å­˜ï¼‰                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è¾“å…¥/è¾“å‡ºç¼“å†²åŒº                          â”‚
â”‚ - input (784 bytes)                     â”‚
â”‚ - output (10 bytes)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ä¼˜åŒ–æŠ€å·§**:
- ä¸­é—´å¼ é‡å¯ä»¥é‡ç”¨ï¼ˆè®¡ç®—å®Œé‡Šæ”¾ï¼‰
- ä½¿ç”¨ `arena_used_bytes()` è·å–å®é™…ä½¿ç”¨é‡
- è®¾ç½®ä¸ºå®é™…ä½¿ç”¨é‡çš„ 1.2-1.5 å€ç•™ä½™é‡

---

## âš ï¸ å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### é—®é¢˜ 1: ç¼–è¯‘é”™è¯¯ "undefined reference to..."

**é”™è¯¯ä¿¡æ¯**:
```
undefined reference to `tflite::MicroInterpreter::AllocateTensors()'
```

**åŸå› **: é“¾æ¥é¡ºåºé”™è¯¯æˆ–åº“æœªæ„å»º

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. ç¡®ä¿åº“å·²æ„å»º
make lib

# 2. æ£€æŸ¥åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls -lh tflite-micro/gen/osx_arm64_default_gcc/lib/libtensorflow-microlite.a

# 3. ç¡®ä¿é“¾æ¥é¡ºåºæ­£ç¡®ï¼ˆ.a æ–‡ä»¶åœ¨æºæ–‡ä»¶ä¹‹åï¼‰
clang++ model_inference.cc model_data.cc -o mnist_micro libtensorflow-microlite.a
```

### é—®é¢˜ 2: è¿è¡Œæ—¶å´©æºƒ "Segmentation fault"

**ç—‡çŠ¶**: `./mnist_micro` ç›´æ¥å´©æºƒ

**å¯èƒ½åŸå› **:

1. **Tensor Arena å¤ªå°**:
```cpp
// å¢åŠ  arena å¤§å°
constexpr int kTensorArenaSize = 100 * 1024;  // ä» 60KB å¢åŠ åˆ° 100KB
```

2. **è¾“å…¥æ•°æ®ç±»å‹ä¸åŒ¹é…**:
```cpp
// æ£€æŸ¥æ¨¡å‹è¾“å…¥ç±»å‹
const auto* tin_fb = sg->tensors()->Get(in_index);
if (tin_fb->type() == tflite::TensorType_INT8) {
  // ä½¿ç”¨ INT8 è¾“å…¥
} else {
  // ä½¿ç”¨ Float32 è¾“å…¥
}
```

3. **ç®—å­æœªæ³¨å†Œ**:
```cpp
// åœ¨ Invoke() å‰æ£€æŸ¥
for (uint32_t i = 0; i < subgraph->operators()->size(); ++i) {
  const auto* op = subgraph->operators()->Get(i);
  const auto* oc = opcodes->Get(op->opcode_index());
  const auto builtin = static_cast<tflite::BuiltinOperator>(oc->builtin_code());
  
  const TFLMRegistration* reg = resolver.FindOp(builtin);
  if (reg == nullptr || reg->invoke == nullptr) {
    MicroPrintf("ERROR: Missing kernel for builtin=%d", (int)builtin);
    return 99;
  }
}
```

### é—®é¢˜ 3: æ¨ç†ç»“æœä¸æ­£ç¡®

**ç—‡çŠ¶**: é¢„æµ‹ç±»åˆ«å§‹ç»ˆä¸º 0 æˆ–éšæœºå€¼

**è°ƒè¯•æ­¥éª¤**:

1. **éªŒè¯è¾“å…¥é‡åŒ–**:
```cpp
// æ‰“å°é‡åŒ–åçš„è¾“å…¥å€¼
for (int i = 0; i < 10; ++i) {
  MicroPrintf("input[%d] = %d", i, (int)input->data.int8[i]);
}
// åº”è¯¥çœ‹åˆ° -128 åˆ° 127 ä¹‹é—´çš„å€¼ï¼Œä¸æ˜¯å…¨ 0
```

2. **æ£€æŸ¥è¾“å‡ºèŒƒå›´**:
```cpp
for (int i = 0; i < 10; ++i) {
  MicroPrintf("output[%d] = %d", i, (int)output->data.int8[i]);
}
// åº”è¯¥æœ‰ä¸€ä¸ªå€¼æ˜æ˜¾å¤§äºå…¶ä»–å€¼
```

3. **å¯¹æ¯” Python TFLite æ¨ç†**:
```python
# ä½¿ç”¨ç›¸åŒè¾“å…¥åœ¨ Python ä¸­æµ‹è¯•
interpreter = tf.lite.Interpreter(model_path="mnist_model_quantized.tflite")
interpreter.allocate_tensors()
interpreter.set_tensor(0, quantized_input)
interpreter.invoke()
output = interpreter.get_tensor(10)
print("Python output:", output)
```

### é—®é¢˜ 4: å†…å­˜æ³„æ¼æˆ–æº¢å‡º

**ç—‡çŠ¶**: é•¿æ—¶é—´è¿è¡Œåå´©æºƒ

**æ£€æŸ¥æ–¹æ³•**:
```bash
# ä½¿ç”¨ AddressSanitizer
make clean
make LDFLAGS="-fsanitize=address" all
./mnist_micro
```

---

## ğŸ§ª éªŒè¯æµ‹è¯•

### 1. å•å…ƒæµ‹è¯•ï¼ˆéªŒè¯é‡åŒ–æ­£ç¡®æ€§ï¼‰

```cpp
void test_quantization() {
  float scale = 0.003922f;
  int zero_point = -128;
  
  // æµ‹è¯•ç™½è‰²åƒç´  (255)
  uint8_t white_pixel = 255;
  float normalized = white_pixel / 255.0f;  // 1.0
  int8_t quantized = std::round(normalized / scale + zero_point);
  assert(quantized == 127);  // INT8 æœ€å¤§å€¼
  
  // æµ‹è¯•é»‘è‰²åƒç´  (0)
  uint8_t black_pixel = 0;
  normalized = black_pixel / 255.0f;  // 0.0
  quantized = std::round(normalized / scale + zero_point);
  assert(quantized == -128);  // INT8 æœ€å°å€¼
  
  MicroPrintf("Quantization test passed!");
}
```

### 2. ç«¯åˆ°ç«¯æµ‹è¯•ï¼ˆä¸ Python å¯¹æ¯”ï¼‰

**Python ç«¯**:
```python
import numpy as np
import tensorflow as tf

# åŠ è½½æ¨¡å‹
interpreter = tf.lite.Interpreter(model_path="mnist_model_quantized.tflite")
interpreter.allocate_tensors()

# ç”Ÿæˆç›¸åŒçš„æµ‹è¯•å›¾åƒ
img = np.zeros((28, 28), dtype=np.uint8)
img[4:24, 13:16] = 255  # ç™½è‰²ç«–çº¿

# é‡åŒ–
input_details = interpreter.get_input_details()
scale = input_details[0]['quantization'][0]
zero_point = input_details[0]['quantization'][1]
quantized = np.round(img.flatten() / 255.0 / scale + zero_point).astype(np.int8)

# æ¨ç†
interpreter.set_tensor(input_details[0]['index'], quantized.reshape(1, 28, 28, 1))
interpreter.invoke()
output = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])

print("Python prediction:", np.argmax(output))  # åº”è¯¥è¾“å‡º 1
```

**C++ ç«¯**:
```bash
./mnist_micro  # åº”è¯¥è¾“å‡º "Predicted class = 1"
```

### 3. æ€§èƒ½åŸºå‡†æµ‹è¯•

```cpp
#include <chrono>

auto start = std::chrono::high_resolution_clock::now();
interpreter.Invoke();
auto end = std::chrono::high_resolution_clock::now();

auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start);
MicroPrintf("Inference time: %lld us", duration.count());
```

**é¢„æœŸæ€§èƒ½**:
- macOS ARM64: ~1-3 ms
- å¾®æ§åˆ¶å™¨ (STM32F7 @216MHz): ~50-100 ms

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. ç¼–è¯‘ä¼˜åŒ–

```makefile
# è°ƒè¯•æ¨¡å¼ï¼ˆå¼€å‘æ—¶ï¼‰
CXXFLAGS := -O0 -g -std=c++17 -DTF_LITE_MICRO_DEBUG_LOG

# å‘å¸ƒæ¨¡å¼ï¼ˆéƒ¨ç½²æ—¶ï¼‰
CXXFLAGS := -O3 -std=c++17 -DNDEBUG -DTF_LITE_STATIC_MEMORY -flto
```

### 2. å†…å­˜ä¼˜åŒ–

```cpp
// ç²¾ç¡®è®¡ç®— arena å¤§å°
int required_size = interpreter.arena_used_bytes();
int optimal_size = required_size * 1.2;  // ç•™ 20% ä½™é‡
MicroPrintf("Optimal arena size: %d bytes", optimal_size);
```

### 3. ç®—å­ä¼˜åŒ–

```cpp
// ä½¿ç”¨ä¼˜åŒ–çš„ç®—å­å®ç°ï¼ˆå¦‚æœç›®æ ‡å¹³å°æ”¯æŒï¼‰
#define TFLITE_MICRO_USE_OPTIMIZED_KERNELS
```

---

## ğŸ“ è¿è¡Œæ£€æŸ¥æ¸…å•

**ç¯å¢ƒå‡†å¤‡**:
- [ ] å…‹éš† tflite-micro ä»“åº“
- [ ] å®‰è£… Bazel (ç”¨äºç”Ÿæˆç®—å­è§£æå™¨)
- [ ] ç¡®è®¤ `mnist_model_quantized.tflite` å­˜åœ¨

**ç”Ÿæˆä¾èµ–æ–‡ä»¶**:
- [ ] è¿è¡Œ `bash transToArray.sh`
- [ ] æ£€æŸ¥ç”Ÿæˆ `model_data.cc` å’Œ `model_data.h`
- [ ] è¿è¡Œ `bash find.sh`
- [ ] æ£€æŸ¥ç”Ÿæˆ `op_resolver/gen_micro_mutable_op_resolver.h`

**æ„å»ºå’Œè¿è¡Œ**:
- [ ] è¿è¡Œ `make lib` (æ„å»º TFLM åº“)
- [ ] è¿è¡Œ `make all` (ç¼–è¯‘æ¨ç†ç¨‹åº)
- [ ] è¿è¡Œ `./mnist_micro`
- [ ] éªŒè¯è¾“å‡º "Predicted class = 1"

**æ€§èƒ½éªŒè¯**:
- [ ] Arena ä½¿ç”¨ç‡ < 50%
- [ ] æ¨ç†æ—¶é—´ < 10 ms (macOS)
- [ ] å†…å­˜å³°å€¼ < 100 KB

---

## ğŸ¯ ç§»æ¤åˆ°çœŸå®åµŒå…¥å¼è®¾å¤‡

### STM32 å¹³å°ç¤ºä¾‹

```cpp
// æ›¿æ¢å†…å­˜åˆ†é…æ–¹å¼
static uint8_t tensor_arena[8*1024] __attribute__((section(".ccmram")));

// æ›¿æ¢æ—¥å¿—è¾“å‡º
#define MicroPrintf(...) printf(__VA_ARGS__)

// æ›¿æ¢éšæœºæ•°ç”Ÿæˆ
uint8_t GetRandomPixel() {
  return (uint8_t)(HAL_GetTick() % 256);
}
```

### Arduino å¹³å°ç¤ºä¾‹

```cpp
#include <TensorFlowLite.h>
#include "model_data.h"

void setup() {
  Serial.begin(115200);
  // åˆå§‹åŒ–æ¨ç†
}

void loop() {
  // ä»ä¼ æ„Ÿå™¨è¯»å–æ•°æ®
  // æ‰§è¡Œæ¨ç†
  // è¾“å‡ºç»“æœ
  delay(1000);
}
```

---

## ğŸ“š å‚è€ƒèµ„æº

- [TFLite Micro å®˜æ–¹æ–‡æ¡£](https://github.com/tensorflow/tflite-micro)
- [TFLite Micro API å‚è€ƒ](https://www.tensorflow.org/lite/microcontrollers)
- [FlatBuffers æ–‡æ¡£](https://google.github.io/flatbuffers/)
- [CMSIS-NN ä¼˜åŒ–åº“](https://github.com/ARM-software/CMSIS-NN)
- [TinyML ä¹¦ç±](https://tinyml.org/)

---

## ğŸ† é¡¹ç›®æ€»ç»“

### å…³é”®æˆæœ

âœ… **æ¨¡å‹å‹ç¼©**: 286 KB â†’ 25 KB (11.57x)  
âœ… **ç²¾åº¦ä¿æŒ**: é‡åŒ–æŸå¤± < 0.01%  
âœ… **å†…å­˜æ•ˆç‡**: ä»…éœ€ 8.5 KB è¿è¡Œæ—¶å†…å­˜  
âœ… **è·¨å¹³å°**: macOS å¼€å‘ â†’ åµŒå…¥å¼éƒ¨ç½²  

### æŠ€æœ¯æ ˆ

```
è®­ç»ƒç¯å¢ƒ: TensorFlow 2.16 + Keras 3
è½¬æ¢ç¯å¢ƒ: TensorFlow 2.15 + TFLite Converter
éƒ¨ç½²ç¯å¢ƒ: TFLite Micro + C++17
ç›®æ ‡å¹³å°: macOS ARM64 (å¯ç§»æ¤åˆ° MCU)
```

### å®Œæ•´æµç¨‹å›é¡¾

```
MNIST æ•°æ®é›†
    â†“
[Part 1] Keras è®­ç»ƒ â†’ mnist_cnn_model.keras (98.8% å‡†ç¡®ç‡)
    â†“ å¯¼å‡ºæƒé‡
[Part 2] TFLite è½¬æ¢ â†’ mnist_model_quantized.tflite (97.7% å‡†ç¡®ç‡, 25KB)
    â†“ è½¬ C æ•°ç»„
[Part 3] TFLM éƒ¨ç½² â†’ mnist_micro (åµŒå…¥å¼æ¨ç†, 8.5KB å†…å­˜)
```

ğŸ‰ **æ­å–œå®Œæˆä»è®­ç»ƒåˆ°åµŒå…¥å¼éƒ¨ç½²çš„å®Œæ•´ ML æµç¨‹ï¼**
