# Part 2: æ¨¡å‹è½¬æ¢è¯¦ç»†è¯´æ˜æ–‡æ¡£

## ğŸ“Œ æ¦‚è¿°

**ç›®æ ‡**: å°† Keras 3 è®­ç»ƒçš„æ¨¡å‹è½¬æ¢ä¸º TensorFlow Lite æ ¼å¼ï¼ˆfloat32 å’Œ int8 é‡åŒ–ç‰ˆæœ¬ï¼‰

**è¾“å…¥**: 
- `mnist_cnn.weights.h5` (ä» Part 1 å¯¼å‡ºçš„æƒé‡)
- MNIST æµ‹è¯•æ•°æ®é›†ï¼ˆç”¨äºé‡åŒ–æ ¡å‡†ï¼‰

**è¾“å‡º**:
- `mnist_model.tflite` (float32 ç‰ˆæœ¬, ~88 KB)
- `mnist_model_quantized.tflite` (int8 é‡åŒ–ç‰ˆæœ¬, ~25 KB)
- `part2_summary.json` (è½¬æ¢æ€»ç»“æŠ¥å‘Š)

---

## ğŸ› ï¸ ç¯å¢ƒè¦æ±‚

### è½¯ä»¶ä¾èµ–
```bash
# Conda ç¯å¢ƒåç§°: mls-a11
TensorFlow: 2.15.x (æ³¨æ„ï¼šå¿…é¡»æ˜¯ 2.15ï¼Œä¸èƒ½æ˜¯ 2.16)
NumPy: æœ€æ–°ç¨³å®šç‰ˆ
Python: 3.9 æˆ– 3.10
```

### ç¯å¢ƒé…ç½®
```bash
conda create -n mls-a11 python=3.10
conda activate mls-a11
pip install tensorflow==2.15.0 numpy
```

### âš ï¸ ç‰ˆæœ¬å…¼å®¹æ€§è¯´æ˜
| ç¯å¢ƒ | TensorFlow | Keras | ç”¨é€” |
|------|------------|-------|------|
| mls-trans | 2.16.x | 3.x | æ¨¡å‹è®­ç»ƒ (Part 1) |
| mls-a11 | 2.15.x | 2.15 (tf.keras) | TFLite è½¬æ¢ (Part 2) |

**ä¸ºä»€ä¹ˆéœ€è¦ä¸¤ä¸ªç¯å¢ƒï¼Ÿ**
- Keras 3 æ¨¡å‹æ— æ³•ç›´æ¥è¢« TF 2.15 çš„ TFLite è½¬æ¢å™¨è¯†åˆ«
- TF 2.15 çš„ TFLite è½¬æ¢å™¨æ›´ç¨³å®šï¼Œç‰¹åˆ«æ˜¯é‡åŒ–åŠŸèƒ½

---

## ğŸ“‚ æ–‡ä»¶è¯´æ˜

### ä¸»æ–‡ä»¶: `part2_tflite_from_weights.py`

**æ–‡ä»¶ç»“æ„**:
```python
part2_tflite_from_weights.py
â”œâ”€â”€ set_seed()                      # è®¾ç½®éšæœºç§å­ï¼ˆå¯å¤ç°æ€§ï¼‰
â”œâ”€â”€ load_and_preprocess_data()      # åŠ è½½ MNIST æ•°æ®
â”œâ”€â”€ build_mnist_cnn()               # é‡å»ºæ¨¡å‹æ¶æ„
â”œâ”€â”€ representative_data_gen()       # é‡åŒ–æ ¡å‡†æ•°æ®ç”Ÿæˆå™¨
â”œâ”€â”€ convert_to_tflite_from_model()  # è½¬æ¢ä¸º TFLite
â”œâ”€â”€ analyze_model_size()            # åˆ†ææ¨¡å‹å¤§å°
â”œâ”€â”€ test_tflite_accuracy()          # æµ‹è¯• TFLite æ¨¡å‹å‡†ç¡®ç‡
â””â”€â”€ main()                          # ä¸»æ‰§è¡Œæµç¨‹
```

---

## ğŸ”„ è½¬æ¢æµç¨‹è¯¦è§£

### å®Œæ•´å·¥ä½œæµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 0: åœ¨ TF 2.16/Keras 3 ç¯å¢ƒå¯¼å‡ºæƒé‡                    â”‚
â”‚  keras.Model â†’ mnist_cnn.weights.h5                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 1: åˆ‡æ¢åˆ° TF 2.15 ç¯å¢ƒ                                 â”‚
â”‚  conda activate mls-a11                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 2: é‡å»ºæ¨¡å‹æ¶æ„ (tf.keras)                             â”‚
â”‚  build_mnist_cnn() â†’ ç›¸åŒçš„ç½‘ç»œç»“æ„                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 3: åŠ è½½æƒé‡                                            â”‚
â”‚  model.load_weights("mnist_cnn.weights.h5")                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 4: è½¬æ¢ä¸º Float32 TFLite                               â”‚
â”‚  TFLiteConverter.from_keras_model(model)                    â”‚
â”‚  â†’ mnist_model.tflite (~88 KB)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 5: è½¬æ¢ä¸º INT8 é‡åŒ– TFLite                             â”‚
â”‚  + ä½¿ç”¨ä»£è¡¨æ€§æ•°æ®é›†æ ¡å‡†                                      â”‚
â”‚  + è®¾ç½®é‡åŒ–é€‰é¡¹                                              â”‚
â”‚  â†’ mnist_model_quantized.tflite (~25 KB)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 6: è¯„ä¼°è½¬æ¢åçš„æ¨¡å‹                                    â”‚
â”‚  - æµ‹è¯•å‡†ç¡®ç‡ (float32: 97.74%, int8: 97.73%)               â”‚
â”‚  - åˆ†ææ¨¡å‹å¤§å°                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ å…³é”®æ­¥éª¤è¯¦è§£

### Step 0: å¯¼å‡ºæƒé‡ï¼ˆåœ¨ TF 2.16 ç¯å¢ƒï¼‰

```python
import keras
m = keras.saving.load_model("mnist_cnn_model.keras")
m.save_weights("mnist_cnn.weights.h5")
print("OK: mnist_cnn.weights.h5")
```

**è¾“å‡ºæ–‡ä»¶**: `mnist_cnn.weights.h5`
- **æ ¼å¼**: HDF5
- **å†…å®¹**: ä»…åŒ…å«æƒé‡å‚æ•°ï¼ˆä¸å«æ¶æ„ï¼‰
- **å¤§å°**: ~86 KB

---

### Step 1-3: é‡å»ºæ¨¡å‹å¹¶åŠ è½½æƒé‡

```python
def build_mnist_cnn():
    """é‡å»ºä¸ Part 1 å®Œå…¨ç›¸åŒçš„æ¨¡å‹æ¶æ„"""
    inputs = keras.Input(shape=(28, 28, 1))
    x = keras.layers.Conv2D(8, 3, activation="relu")(inputs)
    x = keras.layers.MaxPooling2D(2)(x)
    x = keras.layers.Flatten()(x)
    x = keras.layers.Dense(16, activation="relu")(x)
    outputs = keras.layers.Dense(10, activation="softmax")(x)
    model = keras.Model(inputs, outputs, name="mnist_cnn")
    return model

model = build_mnist_cnn()
model.load_weights("mnist_cnn.weights.h5")
```

**å…³é”®ç‚¹**:
- âœ… ä½¿ç”¨ **Functional API** æ„å»ºï¼ˆæ›´çµæ´»ï¼‰
- âœ… æ¶æ„å¿…é¡»ä¸ Part 1 **å®Œå…¨ä¸€è‡´**ï¼ˆå±‚æ•°ã€å‚æ•°ã€æ¿€æ´»å‡½æ•°ï¼‰
- âœ… ä¸éœ€è¦ `compile()`ï¼ˆè½¬æ¢æ—¶ä¸éœ€è¦ä¼˜åŒ–å™¨ï¼‰

---

### Step 4: Float32 TFLite è½¬æ¢

```python
def convert_to_tflite_from_model(model, quantize=False):
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    if not quantize:
        return converter.convert()  # é»˜è®¤ float32
    # ... é‡åŒ–é€»è¾‘è§ä¸‹èŠ‚
```

**è½¬æ¢è¿‡ç¨‹**:
1. åˆ›å»ºè½¬æ¢å™¨å¯¹è±¡
2. è§£æ Keras æ¨¡å‹å›¾
3. ä¼˜åŒ–è®¡ç®—å›¾ï¼ˆåˆå¹¶ç®—å­ã€å¸¸é‡æŠ˜å ï¼‰
4. ç”Ÿæˆ FlatBuffers æ ¼å¼

**è¾“å‡ºæ–‡ä»¶**: `mnist_model.tflite`
- **å¤§å°**: 88.16 KB
- **ç²¾åº¦**: Float32
- **å‡†ç¡®ç‡**: 97.74%

---

### Step 5: INT8 é‡åŒ–è½¬æ¢ï¼ˆæ ¸å¿ƒï¼‰

#### 5.1 ä»€ä¹ˆæ˜¯é‡åŒ–ï¼Ÿ

**é‡åŒ–å…¬å¼**:
```
quantized_value = round(real_value / scale) + zero_point
```

**å¥½å¤„**:
- ğŸ“¦ æ¨¡å‹å¤§å°å‡å°‘ ~75%
- âš¡ æ¨ç†é€Ÿåº¦æå‡ 2-4xï¼ˆæ•´æ•°è¿ç®—æ›´å¿«ï¼‰
- ğŸ”‹ åŠŸè€—é™ä½ï¼ˆåµŒå…¥å¼è®¾å¤‡å‹å¥½ï¼‰

**ä»£ä»·**:
- ç²¾åº¦æŸå¤± ~0.01%ï¼ˆé€šå¸¸å¯æ¥å—ï¼‰

#### 5.2 ä»£è¡¨æ€§æ•°æ®é›†

```python
def representative_data_gen(x_train, num_samples=300):
    """ç”Ÿæˆç”¨äºé‡åŒ–æ ¡å‡†çš„æ•°æ®"""
    n = min(num_samples, x_train.shape[0])
    for i in range(n):
        yield [x_train[i:i+1]]  # å¿…é¡»æ˜¯åˆ—è¡¨ï¼ŒåŒ…å«å•ä¸ªæ ·æœ¬
```

**ä½œç”¨**:
- è½¬æ¢å™¨é€šè¿‡è¿™äº›æ ·æœ¬ç»Ÿè®¡æ¯å±‚æ¿€æ´»å€¼çš„èŒƒå›´
- è®¡ç®—æœ€ä¼˜çš„ scale å’Œ zero_point å‚æ•°

**æ¨èæ•°é‡**: 100-500 ä¸ªæ ·æœ¬ï¼ˆæ›´å¤šä¸ä¸€å®šæ›´å¥½ï¼‰

#### 5.3 é‡åŒ–é…ç½®

```python
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = lambda: representative_data_gen(x_train, 300)
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8
converter.inference_output_type = tf.int8
```

**é…ç½®è¯¦è§£**:

| å‚æ•° | å€¼ | å«ä¹‰ |
|------|-----|------|
| `optimizations` | `[tf.lite.Optimize.DEFAULT]` | å¯ç”¨é»˜è®¤ä¼˜åŒ–ï¼ˆæƒé‡é‡åŒ–ï¼‰ |
| `representative_dataset` | æ•°æ®ç”Ÿæˆå™¨ | æä¾›æ ¡å‡†æ•°æ® |
| `target_spec.supported_ops` | `TFLITE_BUILTINS_INT8` | ä»…ä½¿ç”¨ INT8 ç®—å­ |
| `inference_input_type` | `tf.int8` | è¾“å…¥å¼ é‡ä¸º INT8 |
| `inference_output_type` | `tf.int8` | è¾“å‡ºå¼ é‡ä¸º INT8 |

**è¾“å‡ºæ–‡ä»¶**: `mnist_model_quantized.tflite`
- **å¤§å°**: 24.71 KB
- **ç²¾åº¦**: INT8
- **å‡†ç¡®ç‡**: 97.73%

---

## ğŸ“Š æ¨¡å‹åˆ†æ

### å¤§å°å¯¹æ¯”

| æ¨¡å‹æ ¼å¼ | æ–‡ä»¶å¤§å° | å‹ç¼©æ¯” |
|---------|---------|--------|
| Keras (.keras) | 285.93 KB | 1.0x (åŸºå‡†) |
| TFLite Float32 | 88.16 KB | 3.24x |
| TFLite INT8 | 24.71 KB | **11.57x** |

**å…³é”®è§‚å¯Ÿ**:
- Float32 TFLite æ¯” Keras å° 3.2 å€ï¼ˆç§»é™¤è®­ç»ƒç›¸å…³ä¿¡æ¯ï¼‰
- INT8 é‡åŒ–è¿›ä¸€æ­¥å‹ç¼© 3.6 å€ï¼ˆ8 ä½è¡¨ç¤ºæ›¿ä»£ 32 ä½æµ®ç‚¹ï¼‰

### å‡†ç¡®ç‡å¯¹æ¯”

```json
{
  "accuracy": {
    "tflite_float32": 0.9774,
    "tflite_int8": 0.9773
  }
}
```

**ç»“è®º**:
- é‡åŒ–æŸå¤±ä»… **0.01%**ï¼ˆ10,000 å¼ æµ‹è¯•å›¾åƒä¸­å·® 1 å¼ ï¼‰
- å¯¹äºåµŒå…¥å¼éƒ¨ç½²ï¼Œè¿™ä¸ªç²¾åº¦æŸå¤±**å®Œå…¨å¯æ¥å—**

---

## ğŸ” å…³é”®ä»£ç æ·±åº¦è§£æ

### 1. é‡åŒ–è¾“å…¥é¢„å¤„ç†

```python
def _quantize_input(x: np.ndarray, scale: float, zero_point: int) -> np.ndarray:
    """å°†æµ®ç‚¹è¾“å…¥é‡åŒ–ä¸º INT8"""
    if scale == 0: 
        return np.zeros_like(x, dtype=np.int8)
    q = np.round(x / scale + zero_point)
    return np.clip(q, -128, 127).astype(np.int8)
```

**æ­¥éª¤**:
1. `x / scale` â†’ æŒ‰æ¯”ä¾‹ç¼©æ”¾
2. `+ zero_point` â†’ åç§»åˆ° INT8 èŒƒå›´
3. `np.clip(q, -128, 127)` â†’ è£å‰ªåˆ° [-128, 127]
4. `astype(np.int8)` â†’ è½¬æ¢ä¸ºæœ‰ç¬¦å· 8 ä½æ•´æ•°

**ç¤ºä¾‹**:
```python
# å‡è®¾ scale=0.003922, zero_point=-128
# è¾“å…¥åƒç´ å€¼ 255 (ç™½è‰²)
q = round(1.0 / 0.003922 + (-128)) 
  = round(255 - 128) 
  = 127  # INT8 æœ€å¤§å€¼
```

### 2. TFLite æ¨ç†æµ‹è¯•

```python
def test_tflite_accuracy(tflite_model_data, x_test, y_test):
    interpreter = tf.lite.Interpreter(model_content=tflite_model_data)
    interpreter.allocate_tensors()
    
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    
    # è·å–é‡åŒ–å‚æ•°
    in_scale = input_details[0].get("quantization", (0.0, 0))[0]
    in_zero = input_details[0].get("quantization", (0.0, 0))[1]
    
    correct = 0
    for i in range(len(x_test)):
        # é‡åŒ–è¾“å…¥
        x = x_test[i:i+1]
        if input_details[0]["dtype"] == np.int8:
            in_data = _quantize_input(x, float(in_scale), int(in_zero))
        else:
            in_data = x.astype(np.float32)
        
        # æ¨ç†
        interpreter.set_tensor(input_details[0]["index"], in_data)
        interpreter.invoke()
        
        # è§£æè¾“å‡º
        out = interpreter.get_tensor(output_details[0]["index"])
        pred = int(np.argmax(out))
        correct += int(pred == int(y_test[i]))
    
    return correct / len(x_test)
```

**å…³é”®æ­¥éª¤**:
1. åˆ›å»º TFLite è§£é‡Šå™¨
2. åˆ†é…å¼ é‡å†…å­˜
3. è·å–è¾“å…¥/è¾“å‡ºå…ƒæ•°æ®ï¼ˆç±»å‹ã€å½¢çŠ¶ã€é‡åŒ–å‚æ•°ï¼‰
4. é€æ ·æœ¬æ¨ç†å¹¶ç»Ÿè®¡å‡†ç¡®ç‡

---

## âš ï¸ å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### é—®é¢˜ 1: è½¬æ¢å™¨æŠ¥é”™ "No quantization parameters"

**é”™è¯¯ä¿¡æ¯**:
```
ValueError: Cannot set tensor: Got value of type INT8 but expected type FLOAT32
```

**åŸå› **: æœªæä¾› representative_dataset

**è§£å†³æ–¹æ¡ˆ**:
```python
# ç¡®ä¿è®¾ç½®ä»£è¡¨æ€§æ•°æ®é›†
converter.representative_dataset = lambda: representative_data_gen(x_train, 300)
```

### é—®é¢˜ 2: é‡åŒ–åå‡†ç¡®ç‡å¤§å¹…ä¸‹é™ (>5%)

**å¯èƒ½åŸå› **:
- ä»£è¡¨æ€§æ•°æ®é›†ä¸å¤Ÿå¤šæ ·åŒ–
- æ¨¡å‹æœ¬èº«å¯¹é‡åŒ–æ•æ„Ÿ

**è§£å†³æ–¹æ¡ˆ**:
```python
# å¢åŠ ä»£è¡¨æ€§æ•°æ®é›†æ ·æœ¬æ•°
representative_data_gen(x_train, num_samples=1000)

# æˆ–ä½¿ç”¨åŠ¨æ€èŒƒå›´é‡åŒ–ï¼ˆä»…é‡åŒ–æƒé‡ï¼‰
converter.optimizations = [tf.lite.Optimize.DEFAULT]
# ä¸è®¾ç½® target_spec å’Œ inference_*_type
```

### é—®é¢˜ 3: è½¬æ¢æ—¶å‡ºç° "Non-Converted Ops" è­¦å‘Š

**è­¦å‘Šä¿¡æ¯**:
```
Summary on the non-converted ops:
 * 7 ARITH ops
```

**è¯´æ˜**: 
- è¿™æ˜¯æ­£å¸¸çš„ï¼Œ`arith.constant` æ˜¯ MLIR ä¸­é—´è¡¨ç¤ºçš„å¸¸é‡æ“ä½œ
- æœ€ç»ˆä¼šè¢«ä¼˜åŒ–æ‰ï¼Œä¸å½±å“ TFLite æ¨¡å‹

**éªŒè¯æ–¹æ³•**:
```bash
# ä½¿ç”¨ visualize.py æŸ¥çœ‹æ¨¡å‹å›¾
python -m tensorflow.lite.python.visualize mnist_model_quantized.tflite \
    --output_html model_graph.html
```

### é—®é¢˜ 4: æ¨¡å‹æ–‡ä»¶æŸå

**ç—‡çŠ¶**: æ— æ³•åŠ è½½ .tflite æ–‡ä»¶

**æ£€æŸ¥æ–¹æ³•**:
```bash
# éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
xxd mnist_model_quantized.tflite | head -1
# åº”è¯¥çœ‹åˆ° TFLite æ–‡ä»¶å¤´: 54464c33 (TFL3)
```

---

## ğŸ§ª éªŒè¯æµ‹è¯•

### 1. åŸºæœ¬åŠŸèƒ½æµ‹è¯•

```python
# åŠ è½½é‡åŒ–æ¨¡å‹
interpreter = tf.lite.Interpreter(model_path="mnist_model_quantized.tflite")
interpreter.allocate_tensors()

# è·å–è¾“å…¥è¾“å‡ºç»†èŠ‚
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

print("Input shape:", input_details[0]['shape'])
print("Input type:", input_details[0]['dtype'])
print("Output shape:", output_details[0]['shape'])
print("Output type:", output_details[0]['dtype'])
```

**é¢„æœŸè¾“å‡º**:
```
Input shape: [  1  28  28   1]
Input type: <class 'numpy.int8'>
Output shape: [ 1 10]
Output type: <class 'numpy.int8'>
```

### 2. å•æ ·æœ¬æ¨ç†æµ‹è¯•

```python
# å‡†å¤‡æµ‹è¯•å›¾åƒï¼ˆæ•°å­—"1"ï¼‰
test_image = x_test[0:1]  # shape: (1, 28, 28, 1)

# é‡åŒ–è¾“å…¥
scale = input_details[0]['quantization'][0]
zero_point = input_details[0]['quantization'][1]
quantized_input = np.round(test_image / scale + zero_point).astype(np.int8)

# æ¨ç†
interpreter.set_tensor(input_details[0]['index'], quantized_input)
interpreter.invoke()
output = interpreter.get_tensor(output_details[0]['index'])

# è§£æç»“æœ
predicted_class = np.argmax(output)
print(f"Predicted: {predicted_class}, Actual: {y_test[0]}")
```

---

## ğŸ“ è¿è¡Œæ£€æŸ¥æ¸…å•

**ç¯å¢ƒå‡†å¤‡**:
- [ ] ç¡®è®¤å·²å®‰è£… TensorFlow 2.15
- [ ] ç¡®è®¤ `mnist_cnn.weights.h5` æ–‡ä»¶å­˜åœ¨
- [ ] åˆ‡æ¢åˆ° `mls-a11` Conda ç¯å¢ƒ

**æ‰§è¡Œè½¬æ¢**:
- [ ] è¿è¡Œ `python part2_tflite_from_weights.py`
- [ ] æ£€æŸ¥ç”Ÿæˆ `mnist_model.tflite` (~88 KB)
- [ ] æ£€æŸ¥ç”Ÿæˆ `mnist_model_quantized.tflite` (~25 KB)
- [ ] æ£€æŸ¥ç”Ÿæˆ `part2_summary.json`

**ç»“æœéªŒè¯**:
- [ ] Float32 æ¨¡å‹å‡†ç¡®ç‡ > 97%
- [ ] INT8 æ¨¡å‹å‡†ç¡®ç‡ > 97%
- [ ] å‹ç¼©æ¯” > 10x

---

## ğŸ¯ ä¸‹ä¸€æ­¥æ“ä½œ

å®Œæˆ Part 2 åï¼Œå‡†å¤‡è¿›å…¥ Part 3ï¼ˆåµŒå…¥å¼éƒ¨ç½²ï¼‰ï¼š

1. **è½¬æ¢æ¨¡å‹ä¸º C æ•°ç»„**:
   ```bash
   bash transToArray.sh
   ```

2. **ç”Ÿæˆç®—å­è§£æå™¨**:
   ```bash
   bash find.sh
   ```

3. **ç¼–å†™æ¨ç†ä»£ç **: `model_inference.cc`

---

## ğŸ“š å‚è€ƒèµ„æº

- [TFLite è½¬æ¢å™¨å®˜æ–¹æ–‡æ¡£](https://www.tensorflow.org/lite/convert)
- [TFLite é‡åŒ–æŒ‡å—](https://www.tensorflow.org/lite/performance/post_training_quantization)
- [FlatBuffers æ ¼å¼è¯´æ˜](https://google.github.io/flatbuffers/)
- [TFLite æ¨¡å‹ä¼˜åŒ–å·¥å…·åŒ…](https://www.tensorflow.org/model_optimization)
